{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5SG6hbSDjvK1l7qXlOxmI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhislainBisamaza/Machine_learning_calibration_LCS/blob/main/Data_prep_temp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8tBgWmwcrY_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cufflinks as cf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Cex3DRwkfBHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf.set_config_file(offline = True)"
      ],
      "metadata": {
        "id": "bK5qNVIVfCiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43hDxgoufFvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def null_counter(df):\n",
        "    # Check for null values in the whole dataset\n",
        "    print(\"Null values in the whole dataset:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Check for null values for each individual sensor\n",
        "    sensors = df['Name'].unique()\n",
        "    for sensor in sensors:\n",
        "        sensor_df = df[df['Name'] == sensor]\n",
        "        print(f\"\\nNull values for sensor {sensor}:\")\n",
        "        print(sensor_df.isnull().sum())\n",
        "\n",
        "# def convert_todatetime(df):\n",
        "#     \"\"\"This function combines the date and time column of a datframe and creates a pandas datetime object\"\"\"\n",
        "#     return pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'], format='%d.%m.%Y %H:%M')\n",
        "\n",
        "def convert_todatetime(df):\n",
        "    \"\"\"This function combines the date and time column of a datframe and creates a pandas datetime object\"\"\"\n",
        "\n",
        "    df['Date'] = df['Date'].astype(str)\n",
        "    df['Time'] = df['Time'].astype(str)\n",
        "    df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
        "    df['Date'] = df['Date'] - timedelta(hours=3)\n",
        "\n",
        "    return df\n",
        "\n",
        "def strip_time(df, col='Date'):\n",
        "    \"\"\"Covert object to datetime and strip seconds microseconds from the date object\"\"\"\n",
        "    # dt = pd.to_datetime(df[col], format='mixed')\n",
        "    dt = pd.to_datetime(df[col])\n",
        "    df[col] = pd.to_datetime(dt.apply(lambda x: x.strftime('%Y-%m-%d %H:%M')))\n",
        "\n",
        "    return df\n",
        "\n",
        "def date_range(df, col):\n",
        "    \"\"\"Taking a dataframe return the start and end date based on a datetime column\"\"\"\n",
        "    return df[col].min(), df[col].max()\n",
        "\n",
        "def get_frequency(df, thres_mins=10):\n",
        "    \"\"\"This function takes a dataframe and datetime column\n",
        "    determines the frequency of log values\"\"\"\n",
        "\n",
        "    # Convert the 'Date' column to datetime data type\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
        "\n",
        "    # Calculate the time difference between consecutive rows for each sensor\n",
        "    df['TimeDiff'] = df.groupby('Name')['Date'].diff()\n",
        "\n",
        "    # Calculate the frequency of logging for each sensor\n",
        "    sensor_frequency = df.groupby('Name')['TimeDiff'].mean()\n",
        "\n",
        "    # Format the frequency times to the nearest minutes\n",
        "    sensor_frequency = pd.to_timedelta(sensor_frequency).round('T')\n",
        "\n",
        "    # Print the frequency of logging for each sensor\n",
        "    print(\"Frequency of logging for each sensor:\")\n",
        "    print(sensor_frequency)\n",
        "\n",
        "    # Return two dataframes one with values above a certain threshold and another with summary statistics\n",
        "    # Get a DataFrame where the difference between logging times is more than thres_mins minutes\n",
        "    filtered_df = df[df['TimeDiff'].dt.total_seconds() > (thres_mins*60)]\n",
        "\n",
        "    # Group the DataFrame by sensor and calculate the desired statistics\n",
        "    summary_df = df.groupby('Name').agg({'Value': ['count', 'sum', 'mean']})\n",
        "\n",
        "    # Rename the columns\n",
        "    summary_df.columns = ['Count', 'Sum', 'Mean']\n",
        "\n",
        "    return summary_df, filtered_df, df\n",
        "\n",
        "def select_data_range_values(start_date, end_date, df, col='Date', details=False):\n",
        "    \"\"\"This function slices off data for a given date rnage where the start and end date are specified\"\"\"\n",
        "    # Slice off the dataframe matching this condition\n",
        "    sliced_df = df[(df[col] >= start_date) & (df[col] <= end_date)]\n",
        "\n",
        "    if details:\n",
        "        # Check if there are some missing data\n",
        "        start, end = date_range(sliced_df, col)\n",
        "\n",
        "        if start != start_date:\n",
        "            print(f'Mismatch start: Expected {start_date} vs Gotten (from slice) {start}')\n",
        "        if end != end_date:\n",
        "            print(f'Mismatch end: Expected {end_date} vs Gotten (from slice) {end}')\n",
        "\n",
        "    return sliced_df\n",
        "\n",
        "\n",
        "def smooth_data(df, avg='5'):\n",
        "    \"\"\"This function takes a dataframe object and computes 5 minutes average which is based on the frequency of the reference data\n",
        "    it returns this smoothed average\"\"\"\n",
        "\n",
        "    # set the date column as the index\n",
        "    df = df.set_index('Date')\n",
        "\n",
        "    # calculate the average over 5 minutes\n",
        "    df_avg = df['Value'].resample(f'{avg}T').mean()\n",
        "\n",
        "    # Reset the index\n",
        "    df_avg = df_avg.reset_index()\n",
        "\n",
        "    # return the averaged df\n",
        "    return df_avg\n",
        "\n",
        "\n",
        "def precise_frequency(df, col='Date'):\n",
        "    # calculate time difference between consecutive datetimes\n",
        "    time_diffs = df[col].diff()\n",
        "\n",
        "    # Get the frequency of measuremeant as a mean\n",
        "    sensor_frequency = time_diffs.mean()\n",
        "\n",
        "    # count the number of occurrences of each time difference\n",
        "    freq_counts = time_diffs.value_counts()\n",
        "    print(f\"Frequency counts \\n{freq_counts}\")\n",
        "\n",
        "    return pd.to_timedelta(sensor_frequency).round('T'), freq_counts\n",
        "\n",
        "\n",
        "def plot_date_range(combined_df,start_date,end_date,features_list,title,unit,show_diff=False):\n",
        "    \"\"\"\n",
        "    This function helps to plot Sensors data for a specific data range and their difference.\n",
        "    it can be used following this example:\n",
        "    temperature_data_df.loc[start_date:end_date,['hdc_1', 'hdc_2','hdc_average',\"temperature S001544 (degrees Celsius)\"]].iplot(title= \"Monthly HDC sensor temperature data\", xTitle= \"Time\", yTitle= \"degrees Celsius\")\n",
        "    \"\"\"\n",
        "    if(show_diff):\n",
        "        return combined_df.loc[start_date:end_date,features_list].iplot( kind = \"spread\",\n",
        "                                                                        title=\"{} Sensors Data from {} to {} and their Difference\".format(title, start_date,end_date),\n",
        "                                                                        xTitle=\"Time\",\n",
        "                                                                        yTitle= unit)\n",
        "\n",
        "    return combined_df.loc[start_date:end_date,features_list].iplot( title=\"{} Sensors Data from {} to {}\".format(title, start_date,end_date),\n",
        "                                                                     xTitle=\"Time\",\n",
        "                                                                     yTitle= unit)"
      ],
      "metadata": {
        "id": "5gA9dRpLfFy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cBuP9aqOfF1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_df = pd.read_excel(\"WeatherStation Data - 20-06-2023.xlsx\", sheet_name='Temperature')\n",
        "temperature_df = convert_todatetime(temperature_df)\n",
        "temperature_df"
      ],
      "metadata": {
        "id": "fwJcEXj8fF4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensors_list = temperature_df[\"Name\"].unique().tolist()\n",
        "for sensor in sensors_list:\n",
        "    new_dataframe =  temperature_df.loc[temperature_df[\"Name\"] == sensor]\n",
        "    new_dataframe = new_dataframe.set_index(\"Date\")\n",
        "    new_dataframe = new_dataframe.sort_index()\n",
        "    new_dataframe[\"Value\"].iplot(title=\"{} Sensor data\".format(sensor))"
      ],
      "metadata": {
        "id": "TpUQVFGWfF7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWa1N6e9hoPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temperature data information\n",
        "\n",
        "print(\"Temperature data information\")\n",
        "print(\"============================\")\n",
        "\n",
        "# Get date ranges\n",
        "temp_start, temp_end = date_range(temperature_df, 'Date')\n",
        "print(f'Start date: {temp_start} \\nEnd date: {temp_end}')\n",
        "\n",
        "# Get the frequency of measurement\n",
        "freq = get_frequency(temperature_df)"
      ],
      "metadata": {
        "id": "EjAynvVmhoL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq[1]"
      ],
      "metadata": {
        "id": "gKWTCwjahoJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq[2]['TimeDiff'].iplot()"
      ],
      "metadata": {
        "id": "ebRX2wy3hoAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SxdhE4bnlJ8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2VI2KOKOlJ_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# humidity and temperature have the same sensor\n",
        "# group by sensor and create a dictionary of dataframes\n",
        "\n",
        "# temp_sensor_dfs = {sensor: group for sensor, group in sliced_temp.groupby('Name')}\n",
        "\n",
        "# # assert the lengths of extracted dataframes is same as the unique sensors we have\n",
        "# assert len(temp_sensor_dfs) == len(sliced_temp['Name'].unique())\n",
        "\n",
        "# # visualize a sample df [fun gets the name from a sample]\n",
        "# temp_sensor_dfs[sliced_temp.sample(1).values[0,3]]\n",
        "\n",
        "\n",
        "#second_approach\n",
        "\n",
        "temp_sensor_dfs = {sensor: group for sensor, group in sliced_temp.groupby('Name')}\n",
        "assert len(temp_sensor_dfs) == len(sliced_temp['Name'].unique())\n",
        "\n",
        "sample_row = sliced_temp.sample(1)\n",
        "key = sample_row.values[0, 3]\n",
        "\n",
        "if key in temp_sensor_dfs:\n",
        "    selected_group = temp_sensor_dfs[key]\n",
        "    print(selected_group)\n",
        "else:\n",
        "    print(\"Key does not exist in temp_sensor_dfs dictionary.\")"
      ],
      "metadata": {
        "id": "ExRQLRK_lKca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Smooth data for all temperature sensors\n",
        "for sensor in temp_sensor_dfs.keys():\n",
        "    temp_sensor_dfs[sensor] = smooth_data(temp_sensor_dfs[sensor])\n",
        "    precise_frequency(temp_sensor_dfs[sensor])"
      ],
      "metadata": {
        "id": "8wSxJEhDlKen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the temperature reference and the temperature sensors data to form one single dataframe\n",
        "temperature_data_df = temp_hum_ref[[\"timestamp (UTC)\",\"temperature S001544 (degrees Celsius)\",\"humiditysensortemperature S001544 (degrees Celsius)\"]].reset_index(drop=True)\n",
        "temperature_data_df= temperature_data_df.rename(columns={'timestamp (UTC)': 'Date'})\n",
        "\n",
        "for sensor in temp_sensor_dfs.keys():\n",
        "    new_df = temp_sensor_dfs[sensor][[\"Date\", \"Value\"]]\n",
        "\n",
        "    temperature_data_df = temperature_data_df.merge(new_df, on=\"Date\",how='outer')\n",
        "    temperature_data_df = temperature_data_df.rename(columns={\"Value\": sensor})\n",
        "\n",
        "temperature_data_df = temperature_data_df.set_index(\"Date\")\n",
        "temperature_data_df"
      ],
      "metadata": {
        "id": "AbN1s9Y7lKh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temperature_data_df[\"bme_average\"] = temperature_data_df[['bme_1', 'bme_2', 'bme_3']].mean(axis=1)\n",
        "temperature_data_df[\"hdc_average\"] = temperature_data_df[['hdc_1', 'hdc_2']].mean(axis=1)\n",
        "temperature_data_df[\"htu_average\"] = temperature_data_df[['htu_1', 'htu_2', 'htu_3']].mean(axis=1)\n",
        "temperature_data_df[\"sht_average\"] = temperature_data_df[['sht_1', 'sht_2', 'sht_3']].mean(axis=1)"
      ],
      "metadata": {
        "id": "Dql4dL5DlKvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_ref_available_data = len(temperature_data_df[\"temperature S001544 (degrees Celsius)\"].dropna())\n",
        "average_sensors_data = [\"bme_average\",\"hdc_average\",\"htu_average\",\"sht_average\"]\n",
        "print(\"Percentage of available data for each Temperature sensor type compared to the Reference Data\")\n",
        "print(\"================================================================================\")\n",
        "print(\"\")\n",
        "for average in average_sensors_data:\n",
        "    unique_sensor_data = len(temperature_data_df[average].dropna())\n",
        "    percentage = unique_sensor_data*100//temp_ref_available_data\n",
        "    print(\"The available {} sensor data is {} %\".format(average,percentage))"
      ],
      "metadata": {
        "id": "TRY-oAPXlflh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BSGcthwvlfnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_period_temp = temperature_data_df.index.min()\n",
        "end_period_temp = temperature_data_df.index.max()\n",
        "\n",
        "# Long periods\n",
        "start_date = '2021-12-3'\n",
        "end_date = '2022-01-16'\n",
        "\n",
        "# shorter periods\n",
        "short_start_date = '2021-12-16'\n",
        "short_end_date = '2021-12-18'\n",
        "\n",
        "# feature list\n",
        "all_features = temperature_data_df.columns.tolist()\n",
        "all_features"
      ],
      "metadata": {
        "id": "oZMF6NLslfrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}