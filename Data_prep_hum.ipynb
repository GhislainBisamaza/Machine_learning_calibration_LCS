{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuM/NbnscVnId8BWiQlNk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GhislainBisamaza/Machine_learning_calibration_LCS/blob/main/Data_prep_hum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDZ6BZJuiWQ9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cufflinks as cf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pznvc2g0itKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf.set_config_file(offline = True)"
      ],
      "metadata": {
        "id": "2ve3KB9-itlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def null_counter(df):\n",
        "    # Check for null values in the whole dataset\n",
        "    print(\"Null values in the whole dataset:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Check for null values for each individual sensor\n",
        "    sensors = df['Name'].unique()\n",
        "    for sensor in sensors:\n",
        "        sensor_df = df[df['Name'] == sensor]\n",
        "        print(f\"\\nNull values for sensor {sensor}:\")\n",
        "        print(sensor_df.isnull().sum())\n",
        "\n",
        "# def convert_todatetime(df):\n",
        "#     \"\"\"This function combines the date and time column of a datframe and creates a pandas datetime object\"\"\"\n",
        "#     return pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'], format='%d.%m.%Y %H:%M')\n",
        "\n",
        "def convert_todatetime(df):\n",
        "    \"\"\"This function combines the date and time column of a datframe and creates a pandas datetime object\"\"\"\n",
        "\n",
        "    df['Date'] = df['Date'].astype(str)\n",
        "    df['Time'] = df['Time'].astype(str)\n",
        "    df['Date'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
        "    df['Date'] = df['Date'] - timedelta(hours=3)\n",
        "\n",
        "    return df\n",
        "\n",
        "def strip_time(df, col='Date'):\n",
        "    \"\"\"Covert object to datetime and strip seconds microseconds from the date object\"\"\"\n",
        "    # dt = pd.to_datetime(df[col], format='mixed')\n",
        "    dt = pd.to_datetime(df[col])\n",
        "    df[col] = pd.to_datetime(dt.apply(lambda x: x.strftime('%Y-%m-%d %H:%M')))\n",
        "\n",
        "    return df\n",
        "\n",
        "def date_range(df, col):\n",
        "    \"\"\"Taking a dataframe return the start and end date based on a datetime column\"\"\"\n",
        "    return df[col].min(), df[col].max()\n",
        "\n",
        "def get_frequency(df, thres_mins=10):\n",
        "    \"\"\"This function takes a dataframe and datetime column\n",
        "    determines the frequency of log values\"\"\"\n",
        "\n",
        "    # Convert the 'Date' column to datetime data type\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='mixed')\n",
        "\n",
        "    # Calculate the time difference between consecutive rows for each sensor\n",
        "    df['TimeDiff'] = df.groupby('Name')['Date'].diff()\n",
        "\n",
        "    # Calculate the frequency of logging for each sensor\n",
        "    sensor_frequency = df.groupby('Name')['TimeDiff'].mean()\n",
        "\n",
        "    # Format the frequency times to the nearest minutes\n",
        "    sensor_frequency = pd.to_timedelta(sensor_frequency).round('T')\n",
        "\n",
        "    # Print the frequency of logging for each sensor\n",
        "    print(\"Frequency of logging for each sensor:\")\n",
        "    print(sensor_frequency)\n",
        "\n",
        "    # Return two dataframes one with values above a certain threshold and another with summary statistics\n",
        "    # Get a DataFrame where the difference between logging times is more than thres_mins minutes\n",
        "    filtered_df = df[df['TimeDiff'].dt.total_seconds() > (thres_mins*60)]\n",
        "\n",
        "    # Group the DataFrame by sensor and calculate the desired statistics\n",
        "    summary_df = df.groupby('Name').agg({'Value': ['count', 'sum', 'mean']})\n",
        "\n",
        "    # Rename the columns\n",
        "    summary_df.columns = ['Count', 'Sum', 'Mean']\n",
        "\n",
        "    return summary_df, filtered_df, df\n",
        "\n",
        "def select_data_range_values(start_date, end_date, df, col='Date', details=False):\n",
        "    \"\"\"This function slices off data for a given date rnage where the start and end date are specified\"\"\"\n",
        "    # Slice off the dataframe matching this condition\n",
        "    sliced_df = df[(df[col] >= start_date) & (df[col] <= end_date)]\n",
        "\n",
        "    if details:\n",
        "        # Check if there are some missing data\n",
        "        start, end = date_range(sliced_df, col)\n",
        "\n",
        "        if start != start_date:\n",
        "            print(f'Mismatch start: Expected {start_date} vs Gotten (from slice) {start}')\n",
        "        if end != end_date:\n",
        "            print(f'Mismatch end: Expected {end_date} vs Gotten (from slice) {end}')\n",
        "\n",
        "    return sliced_df\n",
        "\n",
        "\n",
        "def smooth_data(df, avg='5'):\n",
        "    \"\"\"This function takes a dataframe object and computes 5 minutes average which is based on the frequency of the reference data\n",
        "    it returns this smoothed average\"\"\"\n",
        "\n",
        "    # set the date column as the index\n",
        "    df = df.set_index('Date')\n",
        "\n",
        "    # calculate the average over 5 minutes\n",
        "    df_avg = df['Value'].resample(f'{avg}T').mean()\n",
        "\n",
        "    # Reset the index\n",
        "    df_avg = df_avg.reset_index()\n",
        "\n",
        "    # return the averaged df\n",
        "    return df_avg\n",
        "\n",
        "\n",
        "def precise_frequency(df, col='Date'):\n",
        "    # calculate time difference between consecutive datetimes\n",
        "    time_diffs = df[col].diff()\n",
        "\n",
        "    # Get the frequency of measuremeant as a mean\n",
        "    sensor_frequency = time_diffs.mean()\n",
        "\n",
        "    # count the number of occurrences of each time difference\n",
        "    freq_counts = time_diffs.value_counts()\n",
        "    print(f\"Frequency counts \\n{freq_counts}\")\n",
        "\n",
        "    return pd.to_timedelta(sensor_frequency).round('T'), freq_counts\n",
        "\n",
        "\n",
        "def plot_date_range(combined_df,start_date,end_date,features_list,title,unit,show_diff=False):\n",
        "    \"\"\"\n",
        "    This function helps to plot Sensors data for a specific data range and their difference.\n",
        "    it can be used following this example:\n",
        "    temperature_data_df.loc[start_date:end_date,['hdc_1', 'hdc_2','hdc_average',\"temperature S001544 (degrees Celsius)\"]].iplot(title= \"Monthly HDC sensor temperature data\", xTitle= \"Time\", yTitle= \"degrees Celsius\")\n",
        "    \"\"\"\n",
        "    if(show_diff):\n",
        "        return combined_df.loc[start_date:end_date,features_list].iplot( kind = \"spread\",\n",
        "                                                                        title=\"{} Sensors Data from {} to {} and their Difference\".format(title, start_date,end_date),\n",
        "                                                                        xTitle=\"Time\",\n",
        "                                                                        yTitle= unit)\n",
        "\n",
        "    return combined_df.loc[start_date:end_date,features_list].iplot( title=\"{} Sensors Data from {} to {}\".format(title, start_date,end_date),\n",
        "                                                                     xTitle=\"Time\",\n",
        "                                                                     yTitle= unit)"
      ],
      "metadata": {
        "id": "1ydv1SKYitnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_jIqJ50xitpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humidity_df = pd.read_excel(\"WeatherStation Data - 20-06-2023.xlsx\", sheet_name='humidity')\n",
        "humidity_df = convert_todatetime(humidity_df)\n",
        "humidity_df"
      ],
      "metadata": {
        "id": "k14UzYaKitrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qWH87du4ittZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensors_list = humidity_df[\"Name\"].unique().tolist()\n",
        "for sensor in sensors_list:\n",
        "    new_dataframe =  humidity_df.loc[humidity_df[\"Name\"] == sensor]\n",
        "    new_dataframe = new_dataframe.set_index(\"Date\")\n",
        "    new_dataframe = new_dataframe.sort_index()\n",
        "    new_dataframe[\"Value\"].iplot(title=\"{} Sensor data\".format(sensor))"
      ],
      "metadata": {
        "id": "dYd2e1-ritvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# humidity data information\n",
        "print(\"Humidity data information\")\n",
        "print(\"==========================\")\n",
        "# Get date ranges\n",
        "hum_start, hum_end = date_range(humidity_df, 'Date')\n",
        "print(f'Start date: {hum_start} \\nEnd date: {hum_end}')\n",
        "\n",
        "# Get the frequency of measurement\n",
        "freq = get_frequency(humidity_df)"
      ],
      "metadata": {
        "id": "Ee_2w9OXityM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LiJKuTW4itz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mohlkt1xit19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xomyck4Nit3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Me6ge-vit6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpsqrsUNit9i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}